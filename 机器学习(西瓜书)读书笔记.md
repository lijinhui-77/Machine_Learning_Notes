# 机器学习(西瓜书)读书笔记

### 主要符号表

| 符号                                              | 含义                                                         |
| ------------------------------------------------- | ------------------------------------------------------------ |
| $x$                                               | 标量                                                         |
| $\boldsymbol{x}$                                  | 向量                                                         |
| $\mathbf{x}$                                      | 变量集                                                       |
| $\mathbf{A}$                                      | 矩阵                                                         |
| $\mathbf{I}$                                      | 单位阵                                                       |
| $\mathcal{X}$                                     | 样本空间或状态空间                                           |
| $\mathcal{D}$                                     | 概率分布                                                     |
| $D$                                               | 数据样本（数据集）                                           |
| $\mathcal{H}$                                     | 假设空间                                                     |
| $H$                                               | 假设集                                                       |
| $\mathfrak{L}$                                    | 学习算法                                                     |
| $(\cdot,\,\cdot,\,\cdot)$                         | 行向量                                                       |
| $(\cdot;\,\cdot;\,\cdot)$                         | 列向量                                                       |
| $(\cdot)^\mathrm{T}$                              | 向量或矩阵转置                                               |
| $\{\cdots\}$                                      | 集合                                                         |
| $|\{\cdots\}|$                                    | 集合$\,\{\cdots\}\,$中元素个数                               |
| $\norm*{\cdot}_p$                                 | $\mathrm{L}_p\,$范数，$p\,$缺省时为$\,\mathrm{L}_2\,$范数    |
| $P(\cdot),\,P(\cdot\,|\,\cdot)$                   | 概率质量函数，条件概率质量函数                               |
| $p(\cdot),\,p(\cdot\,|\,\cdot)$                   | 概率密度函数，条件概率密度函数                               |
| $\mathbb{E}_{\,\cdot\,\sim\mathcal{D}}[f(\cdot)]$ | 函数$\,f(\cdot)\,$对$\,\cdot\,$在分布$\,\mathcal{D}\,$下的数学期望；意义明确时将省略$\,\mathcal{D}\,$和(或)$\,\cdot$ |
| $\mathrm{sup}(\cdot)$                             | 上确界                                                       |
| $\mathbb{I}(\cdot)$                               | 指示函数，在$\,\cdot\,$为真和假时分别取值为$\,1,0$           |
| $\mathrm{sign}(\cdot)$                            | 符号函数，在$\,\cdot<0,\,=0,\,>0\,$时分别取值为$\,-1,0,1$    |

## 第一章 绪论

### 1.1 引言

###### 机器学习 machine learning

​	机器学习是一门致力于研究如何通过计算手段，利用经验(数据)来改善系统自身性能的学科。机器学习的主要研究对象是关于计算机从数据中产生**模型(model)**的算法，即**学习算法(learning algorithm)**。

> 机器学习更形式化的定义：假设用$\,P\,$来评估计算机程序在某任务类$\,T\,$上的性能，若一个程序通过利用经验$\,E\,$在$\,T\,$中任务上获得了性能改善，则我们就说关于$\,T\,$和$\,P\,$，该程序对$\,E\,$进行了学习。

### 1.2 基本术语

###### 属性 attribute

​	也称**特征(feature)**，是反映事件或对象在某方面的表现或性质的事项。

###### 属性值 attribute value

​	属性上的取值。

###### 样本 sample

​	也称**示例(instance)**，是关于一个事件或对象的描述。用**特征向量(feature vector)**作为样本的表示形式。

###### 样本空间 sample space

​	也称**属性空间(attribute space)**或**输入空间**，是属性张成的空间，即样本的特征向量所在的空间。

###### 数据集 dataset

​	用于机器学习的一组示例的集合。

> 一般地，令$\,D=\{x_1,x_2,...,x_m\}\,$表示包含$\,m\,$个示例的数据集，每个示例由$\,d\,$个属性描述，则每个示例$\,x_i=(x_{i1};x_{i2};x_{id})\,$是$\,d\,$维样本空间$\,\mathcal{X}\,$中的一个向量，$\,x_i\in\mathcal{X}\,$，其中$\,x_{ij}\,$是$\,x_i\,$在第$\,j\,$个属性上的取值，$\,d\,$称为样本$\,x_i\,$的**维数(dimensionality)**。

###### 学习 learning

​	也称**训练(training)**，是通过执行某个学习算法从数据中学得模型的过程。

###### 训练样本 training sample

​	也称**训练示例(training instance)**或**训练例**，是训练过程中使用的样本。

###### 训练集 training set

​	训练样本组成的集合。

###### 模型 model

​	也称**学习器(learner)**，是学习算法在给定数据和参数空间上的实例化。

###### 假设 hypothesis

​	学得关于数据某种潜在规律的模型。

###### 真相/真实 ground-truth

​	数据自身的某种潜在规律。

> 学习过程就是为了找出或逼近真相的模型。

###### 标记 label

​	(若存在)关于示例的结果信息。

###### 样例 example

​	拥有标记信息的示例。

###### 标记空间 label space

​	也称**输出空间**，是所有标记的集合。

> 一般地，用$\,(x_i,y_i)\,$表示第$\,i\,$个样例，其中$\,y_i\in\mathcal{Y}\,$是示例$\,x_i\,$在标记空间$\,\mathcal{Y}\,$上的标记。

###### 测试 testing

​	使用模型进行预测的过程。

###### 测试样本 testing sample

​	也称**测试示例(testing instance)**，是预测过程中使用的样本。

###### 聚类 clustering

​	通过学习算法将找出训练集中某些未知的潜在概念从而将训练集划分为若干组，每组称为一个**簇(cluster)**。

---

学习任务分类：

* 按预测结果值的度量尺度：

  一般地，预测任务是希望通过对训练集$\,\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}\,$进行学习，建立一个从输入空间$\,\mathcal{X}\,$到输出空间$\,\mathcal{Y}\,$的映射$\,f:\mathcal{X}\mapsto\mathcal{Y}\,$。对二分类任务，通常令$\,\mathcal{Y}=\{-1,+1\}\,$或$\,\{0,1\}\,$；对多分类任务，$\,|\mathcal{Y}|>2\,$；对回归任务，$\,\mathcal{Y}=\mathbb{R}\,$，$\,\mathbb{R}\,$为实数域。

  * 连续值：回归(regression)
  * 离散值：分类(classification)
    * 只存在两个类别：二分类(binary classification)任务，包含正类(positive class)和反类(negative class)或负类
    * 存在多个类别：多分类(multi-class classification)任务

* 按训练过程是否用到标记信息：

  * 有标记：监督学习(supervised learning)，代表学习任务：分类和回归
  * 无标记：无监督学习(unsupervised learning)，代表学习任务：聚类
  * 部分标记：半监督学习

____

> 机器学习的目标是使学得的模型能很好地适用于新样本/**未见示例(unseen instance)**。

###### 泛化能力 generalization ability

​	学得模型适用于新样本的能力。

###### 数据决定上限，算法逼近上限

​	数据决定模型效果的上限：从数据量的角度说，通常数据量越大模型效果越好，因为数据量大即表示积累的经验多，因此模型学习到的经验也越多，自然表现效果越好。从特征工程的角度说，通常对特征数值化越合理，特征收集越全越细致，模型效果通常越好，因为此时模型更易学得样本之间潜在的规律；

​	而算法则是让模型无限逼近上限：当数据相关的工作已准备充分时，接下来便可用各种可适用的算法从数据中学习其潜在的规律，进而得到模型，不同算法学习得到的模型效果自然有高低之分，效果越好则越逼近上限，即逼近真相。

###### 独立同分布 independent and identically distributed

​	简称**$\,i.i.d\,$**，表示每个样本都是独立地从样本空间中的样本服从的**分布(distribution)**$\,\mathcal{D}\,$上采样获得的。

> 一般而言，训练样本越多，得到的关于$\,\mathcal{D}\,$的信息就越多，就越有可能通过学习获得具有强泛化能力的模型。

### 1.3 假设空间

###### 归纳 induction

​	从特殊到一般的泛化过程，即从具体的事实归结出一般性规律。

###### 演绎 deduction

​	从一般到特殊的特化过程，即从基础原理推演出具体状况。

###### 归纳学习 inductive learning

​	广义的归纳学习大体相当于从样例中学习，而狭义的归纳学习则要求从训练数据中学得**概念(concept)**，因此也称为概念学习或概念形成。概念学习中最基本的是布尔概念学习，即对“是”、“不是”这样的可表示为$\,0/1\,$布尔值的目标概念的学习。

###### 西瓜问题的学习过程

​	学习过程可看作一个在所有假设组成的空间中进行搜索的过程，搜索的目标是找到与训练集**匹配(fit)**的假设。可以有许多策略对以下西瓜问题的假设空间进行搜索，例如自顶向下、从一般到特殊，或是自底向上、从特殊到一般，搜索过程可以不断删除与正例不一致的假设、和(或)与反例一致的假设。最终将会获得与训练集一致(即对所有训练样本能够进行正确判断)的假设，这就是学习的结果。

![图1.1 西瓜问题的假设空间](./机器学习(西瓜书)读书笔记.assets/图1.1 西瓜问题的假设空间.png)

###### 版本空间 version space

​	所有能够拟合训练集的模型构成的集合。

### 1.4 归纳偏好

###### 归纳偏好 inductive bias

​	机器学习算法在学习过程中基于某种领域的知识对某种类型假设的偏好。

> 归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或价值观。算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能。归纳偏好确立的一般性原则：奥卡姆剃刀。

###### 奥卡姆剃刀 Occam's razor

​	一种常用的、自然学科研究中最基本的原则，即“若有多个假设与观察一致，则选最简单的那个”。

###### NFL定理

​	全称**没有免费的午餐定理(No Free Lunch Theorem)**，对任意学习算法$\,\mathfrak{L}_a\,$和$\,\mathfrak{L}_b\,$它们的期望性能总是相同的。
$$
\begin{flalign}
& \mathrlap{设样本空间\,\mathcal{X}\,和假设空间\,\mathcal{H}\,都是离散的，令\,P(h|X,\mathfrak{L}_a)\,表示算示\,\mathfrak{L}_a\,基于训练集\,X\,产生假设\,h\,的概率，\,f\,表示希望学习的真实目标函数} &\\
& ，再令\,E_{ote}(\mathfrak{L}_a|X,f)\,表示\,\mathfrak{L}_a\,在训练集之外的所有样本上的误差，则: &
\end{flalign}
$$

$$
\begin{equation}
E_{ote}(\mathfrak{L}_a|X,f)=\sum_f\sum_h\sum_{x\in\mathcal{X}-X}P(x)\,\mathbb{I}(h(x) \neq f(x))\,P(h|X,\mathfrak{L}_a)
\tag{1.1}
\end{equation}
$$

$$
\begin{flalign}
& \mathrlap{考虑二分类问题，且真实目标函数可以是任何函数\,\mathcal{X}\mapsto\{0,1\}\,，函数空间为\,\,\{0,1\}^{|\mathcal{X}|}，对所有可能的\,f\,按均匀分布对误差求和，有:} &
\end{flalign}
$$

$$
\begin{aligned}
\sum_fE_{ote}(\mathfrak{L}_a|X,f)&=\sum_f\sum_h\sum_{x\in\mathcal{X}-X}P(x)\,\mathbb{I}(h(x) \neq f(x))\,P(h|X,\mathfrak{L}_a)\\
&=\sum_{x\in\mathcal{X}-X}P(x)\sum_hP(h|X,\mathfrak{L}_a)\sum_f\mathbb{I}(h(x) \neq f(x))\\
&=\sum_{x\in\mathcal{X}-X}P(x)\sum_hP(h|X,\mathfrak{L}_a)\frac{1}{2}2^{|\mathcal{X}|}\\
&=\frac{1}{2}2^{|\mathcal{X}|}\sum_{x\in\mathcal{X}-X}P(x)\sum_hP(h|X,\mathfrak{L}_a)
\end{aligned}
$$

$$
\begin{equation}
=2^{|\mathcal{X}|-1}\sum_{x\in\mathcal{X}-X}P(x)\cdot1
\tag{1.2}
\end{equation}
$$

$$
\begin{flalign}
& 式(1.2)显示出，总误差与学习算法无关，对于任意两个学习算法\,\mathfrak{L}_a\,和\,\mathfrak{L}_b\,都有: &
\end{flalign}
$$

$$
\begin{equation}
\sum_fE_{ote}(\mathfrak{L}_a|X,f)=\sum_fE_{ote}(\mathfrak{L}_b|X,f)
\tag{1.3}
\end{equation}
$$

​	NFL定理表明，脱离具体问题，空泛的谈论“什么学习算法好”毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好。要谈论算法的相对优劣，必须要针对具体的学习问题；在某些问题上表现好的学习算法，在另一些问题上可能不尽人意，学习算法自身的归纳偏好与问题是否匹配，往往会起到决定性作用。

### 1.5 发展历程

![图1.5s 机器学习的发展历程](./机器学习(西瓜书)读书笔记.assets/图1.5s 机器学习的发展历程.png)
