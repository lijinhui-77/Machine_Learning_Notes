# 机器学习(西瓜书)读书笔记

### 主要符号表

| 符号                                              | 含义                                                         |
| ------------------------------------------------- | ------------------------------------------------------------ |
| $x$                                               | 标量                                                         |
| $\boldsymbol{x}$                                  | 向量                                                         |
| $\mathbf{x}$                                      | 变量集                                                       |
| $\mathbf{A}$                                      | 矩阵                                                         |
| $\mathbf{I}$                                      | 单位阵                                                       |
| $\mathcal{X}$                                     | 样本空间或状态空间                                           |
| $\mathcal{D}$                                     | 概率分布                                                     |
| $D$                                               | 数据样本（数据集）                                           |
| $\mathcal{H}$                                     | 假设空间                                                     |
| $H$                                               | 假设集                                                       |
| $\mathfrak{L}$                                    | 学习算法                                                     |
| $(\cdot,\,\cdot,\,\cdot)$                         | 行向量                                                       |
| $(\cdot;\,\cdot;\,\cdot)$                         | 列向量                                                       |
| $(\cdot)^\mathrm{T}$                              | 向量或矩阵转置                                               |
| $\{\cdots\}$                                      | 集合                                                         |
| $|\{\cdots\}|$                                    | 集合$\,\{\cdots\}\,$中元素个数                               |
| $\norm*{\cdot}_p$                                 | $\mathrm{L}_p\,$范数，$p\,$缺省时为$\,\mathrm{L}_2\,$范数    |
| $P(\cdot),\,P(\cdot\,|\,\cdot)$                   | 概率质量函数，条件概率质量函数                               |
| $p(\cdot),\,p(\cdot\,|\,\cdot)$                   | 概率密度函数，条件概率密度函数                               |
| $\mathbb{E}_{\,\cdot\,\sim\mathcal{D}}[f(\cdot)]$ | 函数$\,f(\cdot)\,$对$\,\cdot\,$在分布$\,\mathcal{D}\,$下的数学期望；意义明确时将省略$\,\mathcal{D}\,$和(或)$\,\cdot$ |
| $\mathrm{sup}(\cdot)$                             | 上确界                                                       |
| $\mathbb{I}(\cdot)$                               | 指示函数，在$\,\cdot\,$为真和假时分别取值为$\,1,0$           |
| $\mathrm{sign}(\cdot)$                            | 符号函数，在$\,\cdot<0,\,=0,\,>0\,$时分别取值为$\,-1,0,1$    |

## 第一章 绪论

### 1.1 引言

###### 机器学习 machine learning

​	机器学习是一门致力于研究如何通过计算手段，利用经验(数据)来改善系统自身性能的学科。机器学习的主要研究对象是关于计算机从数据中产生**模型(model)**的算法，即**学习算法(learning algorithm)**。

> 机器学习更形式化的定义：假设用$\,P\,$来评估计算机程序在某任务类$\,T\,$上的性能，若一个程序通过利用经验$\,E\,$在$\,T\,$中任务上获得了性能改善，则我们就说关于$\,T\,$和$\,P\,$，该程序对$\,E\,$进行了学习。

### 1.2 基本术语

###### 属性 attribute

​	也称**特征(feature)**，是反映事件或对象在某方面的表现或性质的事项。

###### 属性值 attribute value

​	属性上的取值。

###### 样本 sample

​	也称**示例(instance)**，是关于一个事件或对象的描述。用**特征向量(feature vector)**作为样本的表示形式。

###### 样本空间 sample space

​	也称**属性空间(attribute space)**或**输入空间**，是属性张成的空间，即样本的特征向量所在的空间。

###### 数据集 dataset

​	用于机器学习的一组示例的集合。

> 一般地，令$\,D=\{x_1,x_2,...,x_m\}\,$表示包含$\,m\,$个示例的数据集，每个示例由$\,d\,$个属性描述，则每个示例$\,x_i=(x_{i1};x_{i2};x_{id})\,$是$\,d\,$维样本空间$\,\mathcal{X}\,$中的一个向量，$\,x_i\in\mathcal{X}\,$，其中$\,x_{ij}\,$是$\,x_i\,$在第$\,j\,$个属性上的取值，$\,d\,$称为样本$\,x_i\,$的**维数(dimensionality)**。

###### 学习 learning

​	也称**训练(training)**，是通过执行某个学习算法从数据中学得模型的过程。

###### 训练样本 training sample

​	也称**训练示例(training instance)**或**训练例**，是训练过程中使用的样本。

###### 训练集 training set

​	训练样本组成的集合。

###### 模型 model

​	也称**学习器(learner)**，是学习算法在给定数据和参数空间上的实例化。

###### 假设 hypothesis

​	学得关于数据某种潜在规律的模型。

###### 真相/真实 ground-truth

​	数据自身的某种潜在规律。

> 学习过程就是为了找出或逼近真相的模型。

###### 标记 label

​	(若存在)关于示例的结果信息。

###### 样例 example

​	拥有标记信息的示例。

###### 标记空间 label space

​	也称**输出空间**，是所有标记的集合。

> 一般地，用$\,(x_i,y_i)\,$表示第$\,i\,$个样例，其中$\,y_i\in\mathcal{Y}\,$是示例$\,x_i\,$在标记空间$\,\mathcal{Y}\,$上的标记。

###### 测试 testing

​	使用模型进行预测的过程。

###### 测试样本 testing sample

​	也称**测试示例(testing instance)**，是预测过程中使用的样本。

###### 测试集 testing set

​	测试样本组成的集合。

###### 聚类 clustering

​	通过学习算法将找出训练集中某些未知的潜在概念从而将训练集划分为若干组，每组称为一个**簇(cluster)**。

---

学习任务分类：

* 按预测结果值的度量尺度：

  一般地，预测任务是希望通过对训练集$\,\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}\,$进行学习，建立一个从输入空间$\,\mathcal{X}\,$到输出空间$\,\mathcal{Y}\,$的映射$\,f:\mathcal{X}\mapsto\mathcal{Y}\,$。对二分类任务，通常令$\,\mathcal{Y}=\{-1,+1\}\,$或$\,\{0,1\}\,$；对多分类任务，$\,|\mathcal{Y}|>2\,$；对回归任务，$\,\mathcal{Y}=\mathbb{R}\,$，$\,\mathbb{R}\,$为实数域。

  * 连续值：回归(regression)
  * 离散值：分类(classification)
    * 只存在两个类别：二分类(binary classification)任务，包含正类(positive class)和反类(negative class)或负类
    * 存在多个类别：多分类(multi-class classification)任务

* 按训练过程是否用到标记信息：

  * 有标记：监督学习(supervised learning)，代表学习任务：分类和回归
  * 无标记：无监督学习(unsupervised learning)，代表学习任务：聚类
  * 部分标记：半监督学习

____

> 机器学习的目标是使学得的模型能很好地适用于新样本/**未见示例(unseen instance)**。

###### 泛化能力 generalization ability

​	学得模型适用于新样本的能力。

###### 数据决定上限，算法逼近上限

​	数据决定模型效果的上限：从数据量的角度说，通常数据量越大模型效果越好，因为数据量大即表示积累的经验多，因此模型学习到的经验也越多，自然表现效果越好。从特征工程的角度说，通常对特征数值化越合理，特征收集越全越细致，模型效果通常越好，因为此时模型更易学得样本之间潜在的规律；

​	而算法则是让模型无限逼近上限：当数据相关的工作已准备充分时，接下来便可用各种可适用的算法从数据中学习其潜在的规律，进而得到模型，不同算法学习得到的模型效果自然有高低之分，效果越好则越逼近上限，即逼近真相。

###### 独立同分布 independent and identically distributed

​	简称**$\,i.i.d\,$**，表示每个样本都是独立地从样本空间中的样本服从的**分布(distribution)**$\,\mathcal{D}\,$上采样获得的。

> 一般而言，训练样本越多，得到的关于$\,\mathcal{D}\,$的信息就越多，就越有可能通过学习获得具有强泛化能力的模型。

### 1.3 假设空间

###### 归纳 induction

​	从特殊到一般的泛化过程，即从具体的事实归结出一般性规律。

###### 演绎 deduction

​	从一般到特殊的特化过程，即从基础原理推演出具体状况。

###### 归纳学习 inductive learning

​	广义的归纳学习大体相当于从样例中学习，而狭义的归纳学习则要求从训练数据中学得**概念(concept)**，因此也称为概念学习或概念形成。概念学习中最基本的是布尔概念学习，即对“是”、“不是”这样的可表示为$\,0/1\,$布尔值的目标概念的学习。

###### 西瓜问题的学习过程

​	学习过程可看作一个在所有假设组成的空间中进行搜索的过程，搜索的目标是找到与训练集**匹配(fit)**的假设。可以有许多策略对以下西瓜问题的假设空间进行搜索，例如自顶向下、从一般到特殊，或是自底向上、从特殊到一般，搜索过程可以不断删除与正例不一致的假设、和(或)与反例一致的假设。最终将会获得与训练集一致(即对所有训练样本能够进行正确判断)的假设，这就是学习的结果。

![图1.1 西瓜问题的假设空间](./机器学习(西瓜书)读书笔记.assets/图1.1 西瓜问题的假设空间.png)

###### 版本空间 version space

​	所有能够拟合训练集的模型构成的集合。

### 1.4 归纳偏好

###### 归纳偏好 inductive bias

​	机器学习算法在学习过程中基于某种领域的知识对某种类型假设的偏好。

> 归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或价值观。算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能。归纳偏好确立的一般性原则：奥卡姆剃刀。

###### 奥卡姆剃刀 Occam's razor

​	一种常用的、自然学科研究中最基本的原则，即“若有多个假设与观察一致，则选最简单的那个”。

###### NFL定理

​	全称**没有免费的午餐定理(No Free Lunch Theorem)**，对任意学习算法$\,\mathfrak{L}_a\,$和$\,\mathfrak{L}_b\,$它们的期望性能总是相同的。
$$
\begin{flalign}
& \mathrlap{设样本空间\,\mathcal{X}\,和假设空间\,\mathcal{H}\,都是离散的，令\,P(h|X,\mathfrak{L}_a)\,表示算示\,\mathfrak{L}_a\,基于训练集\,X\,产生假设\,h\,的概率，\,f\,表示希望学习的真实目标函数} &\\
& ，再令\,E_{ote}(\mathfrak{L}_a|X,f)\,表示\,\mathfrak{L}_a\,在训练集之外的所有样本上的误差，则: &
\end{flalign}
$$

$$
\begin{equation}
E_{ote}(\mathfrak{L}_a|X,f)=\sum_f\sum_h\sum_{x\in\mathcal{X}-X}P(x)\,\mathbb{I}(h(x) \neq f(x))\,P(h|X,\mathfrak{L}_a)
\tag{1.1}
\end{equation}
$$

$$
\begin{flalign}
& \mathrlap{考虑二分类问题，且真实目标函数可以是任何函数\,\mathcal{X}\mapsto\{0,1\}\,，函数空间为\,\,\{0,1\}^{|\mathcal{X}|}，对所有可能的\,f\,按均匀分布对误差求和，有:} &
\end{flalign}
$$

$$
\begin{align}
\sum_fE_{ote}(\mathfrak{L}_a|X,f)&=\sum_f\sum_h\sum_{x\in\mathcal{X}-X}P(x)\,\mathbb{I}(h(x) \neq f(x))\,P(h|X,\mathfrak{L}_a)\\
&=\sum_{x\in\mathcal{X}-X}P(x)\sum_hP(h|X,\mathfrak{L}_a)\sum_f\mathbb{I}(h(x) \neq f(x))\\
&=\sum_{x\in\mathcal{X}-X}P(x)\sum_hP(h|X,\mathfrak{L}_a)\frac{1}{2}2^{|\mathcal{X}|}\\
&=\frac{1}{2}2^{|\mathcal{X}|}\sum_{x\in\mathcal{X}-X}P(x)\sum_hP(h|X,\mathfrak{L}_a)
\end{align}
$$

$$
\begin{equation}
=2^{|\mathcal{X}|-1}\sum_{x\in\mathcal{X}-X}P(x)\cdot1
\tag{1.2}
\end{equation}
$$

$$
\begin{flalign}
& 式(1.2)显示出，总误差与学习算法无关，对于任意两个学习算法\,\mathfrak{L}_a\,和\,\mathfrak{L}_b\,都有: &
\end{flalign}
$$

$$
\begin{equation}
\sum_fE_{ote}(\mathfrak{L}_a|X,f)=\sum_fE_{ote}(\mathfrak{L}_b|X,f)
\tag{1.3}
\end{equation}
$$

​	NFL定理表明，脱离具体问题，空泛的谈论“什么学习算法好”毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好。要谈论算法的相对优劣，必须要针对具体的学习问题；在某些问题上表现好的学习算法，在另一些问题上可能不尽人意，学习算法自身的归纳偏好与问题是否匹配，往往会起到决定性作用。

### 1.5 发展历程

![图1.5s 机器学习的发展历程](./机器学习(西瓜书)读书笔记.assets/图1.5s 机器学习的发展历程.png)

## 第二章 模型评估与选择

### 2.1 经验误差与过拟合

###### 误差 error

​	学习器的实际预测输出与样本的真实输出之间的差异。

###### 训练误差 training error

​	也称**经验误差(empirical error)**，是学习器在训练集上的误差。

###### 测试误差 testing error

​	学习器在测试集上的误差，作为泛化误差的近似。

###### 泛化误差 generalization error

​	学习器在新样本上的误差。

> 学习的目标是为了获得泛化误差小的学习器，然而在事先不知道新样本的情况下实际能做的是使经验误差最小化。在多数情况下我们可以得到一个经验误差很小、在训练集上表现很好的学习器，甚至能达到分类错误率为零，分类精度为$\,100\%\,$,但这样的学习器多数情况下泛化性能都不好。

###### 过拟合 overfitting

​	也称**过配**，是指学习器把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质。产生原因是模型的学习能力相对于数据来说过于强大。

###### 欠拟合 underfitting

​	也称**欠配**，是指学习器对训练样本的一般性质尚未学好。 产生的原因是模型的学习能力相对于数据来说过于低下。

![图2.1 过拟合、欠拟合的直观类比](./机器学习(西瓜书)读书笔记.assets/图2.1 过拟合、欠拟合的直观类比.png)

> 过拟合是机器学习面临的关键障碍，各类学习算法都必然带有一些针对过拟合的措施。然而过拟合是无法彻底避免的，我们所做的只是缓解或者说减小其风险。可以大致这样理解：机器学习面临的问题通常是$\,\mathrm{NP}\,$难甚至更难，而有效的学习算法必然是在多项式时间内运行完成，若可彻底避免过拟合，则通过经验误差最小化就能获得最优解，这就意味着我们构造性的证明了“$\,\mathrm{P}=\mathrm{NP}\,$”；因此，只要相信“$\,\mathrm{P}\neq\mathrm{NP}\,$”，过拟合就不可避免。

###### 模型选择 model selection 问题

​	机器学习任务中对学习算法的选择以及模型参数配置的问题。

### 2.2 评估方法

​	常见的模型评估的方法有：**留出法(hold-out)**、**交叉验证法(cross validation)**、**自助法(bootstrapping)**。留出法操作简单最常用；交叉验证法常用于对比同一算法的不同参数配置之间的效果，以及对比不同算法之间的效果；自助法常用于集成学习产生基分类器。

###### 分层采样 stratified sampling

​	数据集划分过程保留类别比例的采样方式。

#### 2.2.1 留出法

​	将数据集$\,D\,$划分为两个互斥的集合，其中一集合个作为训练集$\,S\,$，另一个作为测试集$\,T\,$，即$\,D=S\cup T,\,S\cap T=\varnothing\,$。训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差。由于对数据集存在多种划分方式，单次使用留出法得到的估计结果往往不够稳定，在使用留出法时，一般要采样若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。留出法若训练集$\,S\,$包含绝大多数样本，训练出的模型可能更接近于用$\,D\,$训练出的模型，但评估结果可能不够稳定；若令测试集$\,T\,$多包含一些样本，被评估的模型与用$\,D\,$训练出的模型可能有较大差别，从而降低了评估结果的保真性。常见的做法是将大约$\,2/3\sim4/5\,$的样本用于训练，剩余样本用于测试。

#### 2.2.2 交叉验证法

​	也称$\,k\,$**折交叉验证(k-fold cross validation)**，将数据集$\,D\,$划分为$\,k\,$个大小相似的互斥子集，即$\,D=D_1\cup D_2\cup ...\cup D_k,\,D_i\cap D_j=\varnothing\,(i\neq j)\,$。每个子集$\,D_i\,$都尽可能保持数据分布的一致性，即从$\,D\,$中通过分层采样得到。然后，每次用$\,k-1\,$个子集的并集作为训练集，余下的那个子集作为测试集，这样就可获得$\,k\,$组训练/测试集，从而可进行$\,k\,$组训练和测试，最终返回的是这$\,k\,$次训练结果的均值。由于数据集存在多种划分方式，为减小因样本划分不同而引入的差异，$\,k\,$折交叉验证通常要随机使用不同的划分重复$\,p\,$次，最终的评估结果是这$\,p\,$次$\,k\,$折交叉验证结果的均值。常见的有10次10折交叉验证。

![图2.2 10折交叉验证示意图](./机器学习(西瓜书)读书笔记.assets/图2.2 10折交叉验证示意图.png)

​	**留一法(Leave-One-Out，简称 LOO)**，是样本个数为$\,m\,$，$k=m\,$的交叉验证法的一个特例。留一法不受随机样本划分方式的影响，因为$\,m\,$个样本只有唯一的方式划分为$\,m\,$个子集；留一法使用的训练集与初始数据集相比只少了一个样本，这使得大多数情况下留一法中被评估的模型与期望评估的用$\,D\,$训练出的模型很相似。因此，留一法的评估结构往往被认为比较准确，然而在数据集比较大时，训练$\,m\,$个模型的计算开销可能是难以忍受的。

#### 2.2.3 自助法

​	给定包含$\,m\,$个样本的数据集$\,D\,$，每次随机从$\,D\,$中挑选一个样本，将其拷贝入$\,D'\,$，然后再将该样本放回初始数据集$\,D\,$中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行$\,m\,$次后，得到包含$\,m\,$个样本的数据集$\,D'\,$。显然$\,D\,$中一部分样本会在$\,D'\,$中多次出现，而样本在$\,m\,$次采样中始终不被采到的概率是$\,(1-\frac{1}{m})^m$，取极限得到：
$$
\begin{equation}
\lim_{m\to\infty}\left(1-\frac{1}{m}\right)^m=\frac{1}{e}\approx0.368
\tag{2.1}
\end{equation}
$$
即通过自助采样，初始数据集$\,D\,$中约有$\,36.8\%\,$的样本未出现在采样数据集$\,D'\,$中，将$\,D'\,$作为测试集，$\,D\backslash D'\,$用作测试集；这样，实际评估的模型与期望评估的模型都使用$\,m\,$个训练样本，而有约$\,1/3\,$的样本没在训练集中用于测试，这样的测试结果也称**包外估计(out-of-bag estimate)**。自助法以**自助采样法(bootstrap sampling)**为基础解决了留出法和交叉验证法中因实际评估的模型所使用的训练集比$\,D\,$小，导致一些因训练样本规模不同而产生的估计偏差，且相较与留一法的计算复杂度较低，在数据集较小、难以有效划分训练/测试集时很有用。然而，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此，在初始数据量足够时，留出法和交叉验证法更常用一些。

#### 2.2.4 调参与最终模型

###### 参数调节 parameter tuning

​	简称**调参**，在进行模型评估与选择时对算法参数(超参数)和模型参数进行设定的过程。

###### 验证集 validation set

​	模型评估与选择中用于评估测试的数据集，一般由训练集划分出新的训练集及验证集。

> 给定包含$\,m\,$个样本的数据集$\,D\,$，在模型评估与选择过程中由于需要留出一部分数据进行评估测试，事实上我们只使用了一部分数据训练模型。因此，在模型选择完成后，学习算法和参数配置已选定，此时应该用数据集$\,D\,$重新训练模型。这个模型在训练过程使用了所有$\,m\,$个样本，才是最终的模型。

### 2.3 性能度量

> 对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需要有衡量模型泛化性能的评价标准，这就是**性能度量(performance measure)**。

​	在预测任务中，给定样例集$\,D=\{(x_1,y_1),(x_2,y_2),...,(x_i,y_i)\}\,$，其中$\,y_i\,$是示例$\,x_i\,$的真实标记。要评估学习器$\,f\,$的性能，就要把学习器预测结果$\,f(x)\,$与真实标记$\,y\,$进行比较。

###### 均方误差 mean squared error

​	预测结果与真实标记的偏差平方的均值：
$$
\begin{equation}
E(f;D)=\frac{1}{m}\sum_{i=1}^m(f(x_i)-y_i)^2
\tag{2.2}
\end{equation}
$$
​	更一般的，对于数据分布$\,D\,$和概率密度函数$\,p(\cdot)\,$均方误差可描述为：
$$
\begin{equation}
E(f;\mathcal{D})=\int_{x\sim\mathcal{D}}(f(x)-y)^2\,p(x)\mathrm{d}x
\tag{2.3}
\end{equation}
$$

#### 2.3.1 错误率与精度

###### 错误率 error rate

​	分类错误的样本占总样本的比例：
$$
\begin{equation}
E(f;D)=\frac{1}{m}\sum_{i=1}^m\mathbb{I}(f(x_i)\neq y_i)
\tag{2.4}
\end{equation}
$$
​	更一般的，对于数据分布$\,D\,$和概率密度函数$\,p(\cdot)\,$错误率可描述为：
$$
\begin{equation}
E(f;\mathcal{D})=\int_{x\sim\mathcal{D}}\mathbb{I}(f(x)\neq y)\,p(x)\mathrm{d}x
\tag{2.6}
\end{equation}
$$
###### 精度 accuracy

​	分类正确的样本占总样本的比例，即“$\,1-\,$错误率”：
$$
\begin{align}
acc(f;D)&=\frac{1}{m}\sum_{i=1}^m\mathbb{I}(f(x_i)=y_i) \tag{2.5}\\
&=1-E(f;D)
\end{align}
$$
​	更一般的，对于数据分布$\,D\,$和概率密度函数$\,p(\cdot)\,$精度可描述为：
$$
\begin{align}
acc(f;\mathcal{D})&=\int_{x\sim\mathcal{D}}\mathbb{I}(f(x)=y)\,p(x)\mathrm{d}x \tag{2.7}\\
&=1-E(f;\mathcal{D})
\end{align}
$$

#### 2.3.2 查准率、查全率与$F1$

![表2.1 分类结果混淆矩阵](./机器学习(西瓜书)读书笔记.assets/表2.1 分类结果混淆矩阵.png)

###### 查准率 precision

​	二分类问题中预测结果为正例中真正例的比例：
$$
\begin{equation}
P=\frac{TP}{TP+FP} \tag{2.8}
\end{equation}
$$

###### 查全率 recall

​	二分类问题中真实情况为正例被识别出的比例：
$$
\begin{equation}
R=\frac{TP}{TP+FN} \tag{2.9}
\end{equation}
$$

> 查准率和查全率是一对矛盾的度量。一般来说查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。通常是有在一些简单任务中，才可能使查全率和查准率都很高。

###### 分类过程

​	分类任务中，学习器为测试样本产生一个实值或概率预测的预测结果，将预测值与一个分类**阈值(threshold)**进行比较，若大于阈值为正类，否则为反类。根据学习器的预测结果对样例进行降序排序，排在前面的是学习器认为最可能是正例的样本，排在最后的则是学习器认为最不可能是正例的样本。分类过程就相当于在这个排序中以某个**截断点(cut point)**将样本分为两部分，前一部分判作正例，后一部分则判作反例。

###### $\mathrm{P}$-$\mathrm{R}$曲线

​	根据学习器的预测结果对样例进行降序排序，按此顺序逐个把样本预测结果更新为分类阈值进行分类，则每次可以计算出当前的查全率、查准率。以查准率为纵轴、查全率为横轴作图，就得到了查准率-查全率曲线，显示该曲线的图称为$\mathrm{P}$-$\mathrm{R}$图。

![图2.3 P-R曲线与平衡点示意图](./机器学习(西瓜书)读书笔记.assets/图2.3 P-R曲线与平衡点示意图.png)

​	$\mathrm{P}$-$\mathrm{R}$曲线下面积的大小在一定程度上表征了学习器在查准率和查全率上取得相对双高的比例，若一个学习器的曲线被另一个学习器的曲线完全包住，则可断言后者的性能优与前者。

###### 平衡点 Break-Event Point

​	简称**BEP**，是指$\mathrm{P}$-$\mathrm{R}$曲线中“查准率 = 查全率”时的取值。是查准率、查全率的简单综合性能度量。

###### $F1\,$度量 

​	$F1\,$是基于查准率与查全率的**调和平均(harmonic mean)**：
$$
\begin{align}
&\frac{1}{F1}=\frac{1}{2}\cdot\left(\frac{1}{P}+\frac{1}{R}\right) \\
\Rightarrow\, &F1=\frac{2\times P\times R}{P+R}=\frac{2\times TP}{样例总数+TP-TN} \tag{2.10}
\end{align}
$$

###### $F_\beta\,$度量

​	$F_\beta\,$度量是$F1\,$度量的一般形式，是对查准率与查全率的加权调和平均：
$$
\begin{align}
\frac{1}{F_\beta}&=\frac{1}{1+\beta^2}\cdot\left(\frac{1}{P}+\frac{\beta^2}{R}\right) \\
\Rightarrow\, F_\beta&=\frac{(1+\beta^2)\times P\times R}{(\beta^2\times P)+R} \tag{2.11} \\
&=\frac{1}{\frac{1}{1+\beta^2}\cdot\frac{1}{P}+\frac{\beta^2}{1+\beta^2}\cdot\frac{1}{R}}
\end{align}
$$
​	其中$\,\beta>0\,$度量了查全率对查准率的相对重要性。$\beta=1\,$时退化为标准$\,F1\,$；$\beta>1\,$时查全率有更大影响；$\beta<1\,$时查准率有更大影响。

###### 宏$\,F1\,$ macro-$\,F1$

​	综合考察$\,n\,$个二分类混淆矩阵的查准率和查全率时先计算各混淆矩阵的$\,(P_1,R_1),(P_2,R_2),...,(P_n,R_n)\,$，再计算平均值得到**宏查准率(macro-$P$)**、**宏查全率(macro-$R$)**、宏$\,F1$：
$$
\begin{equation}
\text{macro-}P =\frac{1}{n}\sum_{i=1}^nP_i
\tag{2.12}
\end{equation}
$$

$$
\begin{equation}
\text{macro-}R =\frac{1}{n}\sum_{i=1}^nR_i
\tag{2.13}
\end{equation}
$$

$$
\begin{equation}
\text{macro-}F1=\frac{2\times\text{macro-}P\times\text{macro-}R}{\text{macro-}P+\text{macro-}R}
\tag{2.14}
\end{equation}
$$

###### 微$\,F1\,$ micro-$\,F1$

​	综合考察$\,n\,$个二分类混淆矩阵的查准率和查全率时先计算混淆矩阵各对应元素的均值$\,\overline{TP}$、$\,\overline{FP}$、$\,\overline{TN}$、$\,\overline{FN}$，再计算对应的**微查准率(macro-$P$)**、**微查全率(macro-$R$)**、微$\,F1$：
$$
\begin{equation}
\text{micro-}P=\frac{\overline{TP}}{\overline{TP}+\overline{FP}}
\tag{2.15}
\end{equation}
$$

$$
\begin{equation}
\text{micro-}R=\frac{\overline{TP}}{\overline{TP}+\overline{FN}}
\tag{2.16}
\end{equation}
$$

$$
\begin{equation}
\text{micro-}F1=\frac{2\times\text{micro-}P\times\text{micro-}R}{\text{micro-}P+\text{micro-}R}
\tag{2.17}
\end{equation}
$$

#### 2.3.3 ROC与AUC

###### 真正例率 True Positive Rate

​	二分类问题中真实情况为正例被正确识别的比例(等价于查全率)：
$$
\begin{equation}
\mathrm{TPR}=\frac{TP}{TP+FN} \tag{2.18}
\end{equation}
$$

###### 假正例率 False Positive Rate

​	二分类问题中真实情况为反例被错误识别的比例：
$$
\begin{equation}
\mathrm{FPR}=\frac{FP}{TN+FP} \tag{2.19}
\end{equation}
$$

###### 假反例率 False Negative Rate

​	二分类问题中真实情况为正例被错误识别的比例($\,1-\mathrm{TPR}\,$)：
$$
\begin{equation}
\mathrm{FNR}=\frac{FN}{TP+FN}
\end{equation}
$$

###### 真反例率 True Negative Rate

​	二分类问题中真实情况为反例被正确识别的比例($\,1-\mathrm{FPR}\,$)：
$$
\begin{equation}
\mathrm{TNR}=\frac{TN}{TN+FP}
\end{equation}
$$

###### $\mathrm{ROC}\,$曲线

​	全称**受试者工作特征(Receiver Operating Characteristic)曲线**，根据学习器的预测结果对样例进行降序排序，按此顺序逐个把样本预测结果更新为分类阈值进行分类，则每次可以计算出当前的真正例率、假正例率。以真正例率为纵轴、假正例率为横轴作图，就得到了$\,\mathrm{ROC}\,$曲线，显示该曲线的图称为$\,\mathrm{ROC}\,$图。

![图2.4 ROC曲线与AUC示意图](./机器学习(西瓜书)读书笔记.assets/图2.4 ROC曲线与AUC示意图.png)

​	图 2.4(a)对角线对应于“随机猜测”模型，而点$\,(0,1)\,$则对应于将所有正例排在所有反例之前的“理想模型”。现实任务中通常是利用有限个测试样例来绘制近似的$\,\mathrm{ROC}\,$曲线，如图 2.4(b)：给定$\,m^+\,$个正例和$\,m^-\,$个反例，根据学习器预测结果对样例进行排序，然后把分类阈值设为最大，即把所有样例均预测为反例，此时真正例率和假正例率均为$\,0\,$，在坐标$\,(0,0)\,$处标记一个点，然后将分类阈值依次设置为每个样例的预测值，即依次将每个样例划分为正例。设前一个标记点坐标为$\,(x,y)\,$，当前若为真正例，则对应标记点的坐标为$\,(x,y+\frac{1}{m^+})\,$；当前若为假正例，则对应标记点的坐标为$\,(x+\frac{1}{m^-}),y\,$，然后用线段连接相邻点。$\,\mathrm{ROC}\,$曲线上的每一个点都表示学习器$\,f(s)\,$在特定阈值下构成的一个二分类器，这个二分类器越好，它的假正例率越小，真正例率越大。所以学习器越好，其$\,\mathrm{ROC}\,$曲线上的点越靠近左上角，$\mathrm{AUC}\,$也越大。

###### $\mathrm{AUC}$

​	$\mathrm{AUC}\,$(Area Under ROC Curve)表示$\,\mathrm{ROC}\,$曲线下的面积，是真正例率、假正例率的综合性能度量，$\mathrm{AUC}\,$值越大则对应学习器性能越优。设$\,\mathrm{ROC}\,$曲线是由坐标为$\,\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}\,$的点按序连接而形成$\,(x_1=0,x_m=1)\,$，则$\,\mathrm{AUC}\,$可估算为：
$$
\begin{equation}
\mathrm{AUC}=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-x_i)\cdot(y_i+y_{i+1})
\tag{2.20}
\end{equation}
$$

######  排序损失 rank loss

​	$\mathrm{AUC}\,$考虑的是样本预测的排序质量，因此它与排序误差有紧密联系。给定$\,m^+\,$个正例和$\,m^-\,$个反例，令$\,D^+\,$和$\,D^-\,$分别表示正、反例集合，则排序损失定义为：
$$
\begin{align}
\ell_{rank}&=\frac{1}{m^+m^-}\sum_{x^+\in D^+}\sum_{x^-\in D^-}\left(\mathbb{I}(f(x^+)<f(x^-))+\frac{1}{2}\mathbb{I}(f(x^+)=f(x^-))\right) \tag{2.21} \\
&=\frac{1}{m^+m^-}\sum_{x^+\in D^+}\left[\sum_{x^-\in D^-}\mathbb{I}(f(x^+)<f(x^-))+\frac{1}{2}\cdot\sum_{x^-\in D^-}\mathbb{I}(f(x^+)=f(x^-))\right] \\
&=\sum_{x^+\in D^+}\left[\frac{1}{m^+}\cdot\frac{1}{m^-}\sum_{x^-\in D^-}\mathbb{I}(f(x^+)<f(x^-))+\frac{1}{2}\cdot\frac{1}{m^+}\cdot\frac{1}{m^-}\sum_{x^-\in D^-}\mathbb{I}(f(x^+)=f(x^-))\right] \\
&=\sum_{x^+\in D^+}\frac{1}{2}\cdot\frac{1}{m^+}\cdot\left[\frac{2}{m^-}\sum_{x^-\in D^-}\mathbb{I}(f(x^+)<f(x^-))+\frac{1}{m^-}\sum_{x^-\in D^-}\mathbb{I}(f(x^+)=f(x^-))\right]
\end{align}
$$
​	$\ell_{rank}\,$对应的是$\,\mathrm{ROC}\,$曲线上的面积，若一个正例在$\,\mathrm{ROC}\,$曲线上对应标记点的坐标为$\,(x,y)\,$，则$\,x\,$恰是排序在其之前的反例所占的比例，即假正例率。$\,\ell_{rank}\,$可表示从测试集中抽取正反例对，模型$\,f(x)\,$排序错误的概率，则$\,\mathrm{AUC}\,$便是从测试集中随机抽取正反例对，模型$\,f(x)\,$排序正确的概率，因此有：
$$
\begin{equation}
\mathrm{AUC}=1-\ell_{rank}
\tag{2.22}
\end{equation}
$$

#### 2.3.4 代价敏感错误率与代价曲线

###### 非均等代价 unequal cost

​	不同类型错误所造成的损失不同($\,cost_{01}\neq cost_{10}\,$)则为非均等代价，相同($\,cost_{01}=cost_{10}\,$)则为均等代价。

![表2.2 二分类代价矩阵](./机器学习(西瓜书)读书笔记.assets/表2.2 二分类代价矩阵.png)

###### 代价敏感 cost-sensitive 错误率

​	错误率是在隐式地假设了均等代价下直接计算错误次数，并没有考虑不同错误会造成不同的后果，而在非均等代价下，我们所希望的不再是简单低最小化错误次数，而是希望最小化**总体代价(total cost)**。若将表2.2中的第$\,0\,$类作为正类、第$\,1\,$类作为反类，令$\,D^+\,$与$\,D^-\,$分别代表样例集$\,D\,$的正例子集和反例子集，$m，m^+,m^-\,$分别表示样例数、正样例数和反样例数，正例概率$\frac{m^+}{m}\,$记作$\,p\,$，则代价敏感错误率为：
$$
\begin{align}
E(f;D;cost)&=\frac{1}{m}\left(\sum_{x_i\in D^+}\mathbb{I}(f(x_i)\neq y_i)\times cost_{01}+\sum_{x_i\in D^-}\mathbb{I}(f(x_i)\neq y_i)\times cost_{10}\right) \tag{2.23} \\
&=\frac{1}{m}\left(m^+\times\frac{1}{m^+}\sum_{x_i\in D^+}\mathbb{I}(f(x_i)\neq y_i)\times cost_{01}+m^-\times\frac{1}{m^-}\sum_{x_i\in D^-}\mathbb{I}(f(x_i)\neq y_i)\times cost_{10}\right) \\
&=\frac{m^+}{m}\times\frac{1}{m^+}\sum_{x_i\in D^+}\mathbb{I}(f(x_i)\neq y_i)\times cost_{01}+\frac{m^-}{m}\times\frac{1}{m^-}\sum_{x_i\in D^-}\mathbb{I}(f(x_i)\neq y_i)\times cost_{10} \\
&=p\times\mathrm{FNR}\times cost_{01}+(1-p)\times\mathrm{FPR}\times cost_{10}
\end{align}
$$

###### 正例概率代价

​	在正例样例概率为$\,p\,$的条件下，正例在样例集中的加权占比：
$$
\begin{equation}
P(+)cost=\frac{p\times cost_{01}}{p\times cost_{01}+(1-p)\times cost_{10}}
\tag{2.24}
\end{equation}
$$

###### 归一化代价

​	学习器**代价敏感(sensitive)总代价**为：
$$
\begin{align}
cost_{se}&=TP\times cost_{00}+FN\times cost_{01}+FP\times cost_{10}+TN\times cost_{11} \\
&=m\times p\times\mathrm{FNR}\times cost_{01}+m\times (1-p)\times\mathrm{FPR}\times cost_{10}
\end{align}
$$
​	$cost_{se}\,$的一般化形式为：
$$
\begin{equation}
cost_{se}=p\times\mathrm{FNR}\times cost_{01}+(1-p)\times\mathrm{FPR}\times cost_{10}
\end{equation}
$$
​	当$\,FNR=FPR=1\,$时，即表示所有正例均被预测为反例，所有反例则均被预测为正例，代价达到最大：
$$
\begin{equation}
\text{max}(cost_{se})=p\times cost_{01}+(1-p)\times cost_{10}
\end{equation}
$$
​	在正例样例概率为$\,p\,$的条件下的归一化代价：
$$
\begin{align}
cost_{norm}&=\frac{cost_{se}}{\text{max}(cost_{se})} \\
&=\frac{\mathrm{FNR}\times p\times cost_{01}+\mathrm{FPR}\times(1-p)\times cost_{10}}{p\times cost_{01}+(1-p)\times cost_{10}} \tag{2.25} \\
&=\mathrm{FNR}\times P(+)cost+\mathrm{FPR}\times(1-P(+)cost)
\end{align}
$$

###### 代价曲线

​	代价曲线图的横轴是取值为$\,[0,1]\,$的正例概率代价，纵轴是取值为$\,[0,1]\,$的归一化代价，$\mathrm{ROC}\,$曲线上每一点对应了代价平面上的一条线段，设$\,\mathrm{ROC}\,$曲线上点的坐标为$\,(\mathrm{TPR},\mathrm{FPR})\,$，则可相应计算出$\,\mathrm{FNR}\,$，然后在代价平面上绘制一条从$\,(0,\mathrm{FPR})\,$到$\,(1,\mathrm{FNR})\,$的线段，线段下的面积即表示了该条件下的期望总体代价；如此将$\,\mathrm{ROC}\,$曲线上的每个点转化为代价平面上的一条线段，然后取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价。

![图2.5 代价曲线与期望总体代价](./机器学习(西瓜书)读书笔记.assets/图2.5 代价曲线与期望总体代价.png)

​	基于代价曲线图，可先计算出样例集的$\,P(+)cost\,$值，然后根据计算出来的值在横轴上标记出具体的点，并基于该点画一条垂直于横轴的垂线，与该锤线最先相交(从下往上看)的线段所对应的阈值(每条线段都对应$\,\mathrm{ROC}\,$曲线上的点，而$\,\mathrm{ROC}\,$曲线上的点又对应具体的阈值)即为最佳阈值。

### 2.4 比较检验

	###### 为什么要进行比较检验

​	机器学习性能比较问题比较复杂，涉及几个重要因素：首先，我们希望比较的是泛化性能，然而通过实验评估方法我们获得的是测试性能，两者的对比结果可能未必相同；第二，测试集上的性能与测试集本身的选择有很大关系，且不论使用不同大小的测试集会得到不同的结果，即便用相同大小的测试集，若包含的测试样例不同，测试结果也会有不同；第三，很多机器学习算法本身有一定的随机性，即便用相同的参数设置在同一个测试集上多次运行，其结果也会有不同。从统计学的角度，取得的性能度量的值在本质上仍是一个随机变量，因此并不能简单用比较大小的方法来直接判定算法(或模型)之间的优劣，而需要使用更置信的方法进行判定。

### 2.5 偏差与方差

###### 几个期望运算性质

$$
\begin{align}
&\mathbb{E}[X+Y]=\mathbb{E}[X]+\mathbb{E}[Y] \\
&\mathbb{E}[AX+B]=A\mathbb{E}[X]+B,其中A和B均为常量 \\
&\mathbb{E}[XY]=\mathbb{E}[X]\mathbb{E}[Y],其中X和Y为相互独立的随机变量
\end{align}
$$



###### 偏差-方差分解 bias-variance decomposition

​	偏差-方差分解是对学习算法的期望泛化错误率进行拆解，是解释学习算法泛化性能的一种重要方式。

​	对测试样本$\,x\,$，令$\,y_D\,$为$\,x\,$在数据集中的标记，$y\,$为$\,x\,$的真实标记，$f(x;D)\,$为训练集$\,D\,$上学得模型$\,f\,$在$\,x\,$上的预测输出，设有$\,n\,$个训练集$\,D_1...D_n\,$，这$\,n\,$个训练集都是以独立同分布的方式从样本空间中采集而得的，并且都包含测试样本$\,x\,$，该样本在这$\,n\,$个训练集中的标记分别为$\,y_{D_1},...,y_{D_2}\,$。以回归任务为例，学习算法的期望预测为：
$$
\begin{equation}
\overline{f}(x)=\mathbb{E}_D[f(x;D)]=\frac{1}{n}(f(x;D_1)+...+f(x;D_n))
\tag{2.37}
\end{equation}
$$
​	使用样本数相同的不同训练集产生的方差为：
$$
\begin{equation}
var(x)=\mathbb{E}_D\left[(f(x;D)-\overline{f}(x))^2\right]=\frac{1}{n}\left((f(x;D_1)-\overline{f}(x))^2+...+(f(x;D_n)-\overline{f}(x))^2\right)
\tag{2.38}
\end{equation}
$$
​	噪声为：
$$
\begin{equation}
\varepsilon^2=\mathbb{E}_D\left[(y_D-y)^2\right]=\frac{1}{n}\left((y_{D_1}-y)^2+...+(y_{D_n}-y)^2\right)
\tag{2.39}
\end{equation}
$$
​	期望输出与真实标记的差别称为**偏差(bias)**，即：
$$
\begin{equation}
bias^2(x)=\left(\overline{f}(x)-y\right)^2
\tag{2.40}
\end{equation}
$$
​	假定噪声期望为零，即$\,\mathbb{E}[y_D-y]=0\,$，则可对算法的期望泛化误差进行分解：
$$
\begin{align}
E(f;D)&=\mathbb{E}_D\left[(f(x;D)-y_D)^2\right] \\
&=\mathbb{E}_D\left[(f(x;D)-\overline{f}(x)+\overline{f}(x)-y_D)^2\right] \\
&=\mathbb{E}_D\left[(f(x;D)-\overline{f}(x))^2+(\overline{f}(x)-y_D)^2+2(f(x;D)-\overline{f}(x))(\overline{f}(x)-y_D)\right] \\
&=\mathbb{E}_D\left[(f(x;D)-\overline{f}(x))^2\right]+\mathbb{E}_D\left[(\overline{f}(x)-y_D)^2\right]+\mathbb{E}_D[2(f(x;D)-\overline{f}(x))(\overline{f}(x)-y_D)] \\
&=\mathbb{E}_D\left[(f(x;D)-\overline{f}(x))^2\right]+\mathbb{E}_D\left[(\overline{f}(x)-y_D)^2\right]+\mathbb{E}_D[2f(x;D)\cdot\overline{f}(x)-2\overline{f}(x)\cdot\overline{f}(x)] \\
&+\mathbb{E}_D[2(f(x;D)-\overline{f}(x))\cdot y_D] \\
&=\mathbb{E}_D\left[(f(x;D)-\overline{f}(x))^2\right]+\mathbb{E}_D\left[(\overline{f}(x)-y_D)^2\right]+2\overline{f}(x)\cdot\mathbb{E}_D[f(x;D)]-2\overline{f}(x)\cdot\overline{f}(x) \\
&+2\mathbb{E}_D[(f(x;D)\cdot y_D]-2\overline{f}(x)\cdot\mathbb{E}[y_D] \\
&=\mathbb{E}_D\left[(f(x;D)-\overline{f}(x))^2\right]+\mathbb{E}_D\left[(\overline{f}(x)-y_D)^2\right]+2\mathbb{E}_D[(f(x;D)]\cdot\mathbb{E}[y_D]-2\overline{f}(x)\cdot\mathbb{E}[y_D] \\
&=\mathbb{E}_D\left[(f(x;D)-\overline{f}(x))^2\right]+\mathbb{E}_D\left[(\overline{f}(x)-y_D)^2\right] \\
&=\mathbb{E}_D\left[(f(x;D)-\overline{f}(x))^2\right]+\mathbb{E}_D\left[(\overline{f}(x)-y+y-y_D)^2\right] \\
&=\mathbb{E}_D\left[(f(x;D)-\overline{f}(x))^2\right]+\mathbb{E}_D\left[(\overline{f}(x)-y)^2\right]+\mathbb{E}_D\left[(y-y_D)^2\right]+2\mathbb{E}_D[(\overline{f}(x)-y)(y-y_D)] \\
&=\mathbb{E}_D\left[(f(x;D)-\overline{f}(x))^2\right]+(\overline{f}(x)-y)^2+\mathbb{E}_D\left[(y_D-y)^2\right]+2(\overline{f}(x)-y)\mathbb{E}[(y-y_D)] \\
&=\mathbb{E}_D\left[(f(x;D)-\overline{f}(x))^2\right]+(\overline{f}(x)-y)^2+\mathbb{E}_D\left[(y_D-y)^2\right] \tag{2.41}
\end{align}
$$

$$
\begin{equation}
\Rightarrow E(f;D)=bias^2(x)+var(x)+\varepsilon^2
\tag{2.42}
\end{equation}
$$

​	也就是说，泛化误差可分解为偏差、方差与噪声之和。偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力；方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响；噪声则表达了再当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。偏差-方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。给点学习任务，为了取得好的泛化性能，则需使偏差较小，即能够充分拟合数据，并且使方差较小，即是的数据扰动产生的影响小。

###### 偏差-方差窘境 bias-variance dilemma

​	一般来说，偏差与方差是有冲突的。给定学习任务，假定我们能控制学习算法的训练程度，则在训练不足时，学习器的拟合能力不够强，训练数据的扰动不足以使学习器产生显著变化，此时偏差主导了泛化错误率；随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差逐渐主导了泛化错误率；在训练程度充足后，学习器的拟合能力已非常强，训练数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合。

![图2.9 泛化误差与偏差、方差的关系示意图](./机器学习(西瓜书)读书笔记.assets/图2.9 泛化误差与偏差、方差的关系示意图.png)
